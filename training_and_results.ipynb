{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will implement and train three different types of classifiers to ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Training and Test Datasets\n",
    "train_data = pd.read_csv('datasets/train_preprocessed.csv')\n",
    "test_data  = pd.read_csv('datasets/test_preprocessed.csv')\n",
    "\n",
    "# Load Training and Test Features\n",
    "features_train = pd.read_csv('features/features_train.csv')\n",
    "features_test  = pd.read_csv('features/features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we implemented is the Linear Regression model. We selected this model due to it was used in the UKP paper [1]. We followed their same \"process\" using a 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pearson_corr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m pearson_scorer \u001b[38;5;241m=\u001b[39m make_scorer(\u001b[43mpearson_corr\u001b[49m, greater_is_better\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Linear Regression Model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearRegression()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pearson_corr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "pearson_scorer = make_scorer(pearson_corr, greater_is_better=True)\n",
    "\n",
    "# Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Cross-validation\n",
    "linear_scores = cross_val_score(linear_model, features_train, train_data[\"score\"], cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Linear Regression - Pearson Correlation Scores:\", linear_scores)\n",
    "print(\"Linear Regression - Mean Pearson Correlation:\", linear_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pearson_scorer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Grid Search for Random Forest\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m rf_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(rf_model, rf_params, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[43mpearson_scorer\u001b[49m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m rf_grid\u001b[38;5;241m.\u001b[39mfit(features_train, train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Best Model and Parameters\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pearson_scorer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Parameters\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [5, 10], #None crec que funciona millor\n",
    "    \"min_samples_split\": [2, 5, 7]\n",
    "}\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=10, scoring=pearson_scorer, n_jobs=-1)\n",
    "rf_grid.fit(features_train, train_data[\"score\"])\n",
    "\n",
    "# Best Model and Parameters\n",
    "rf_best_model = rf_grid.best_estimator_\n",
    "rf_best_params = rf_grid.best_params_\n",
    "\n",
    "# Cross-validation with the best model\n",
    "rf_best_scores = cross_val_score(rf_best_model, features_train, train_data[\"score\"], cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Random Forest - Best Parameters:\", rf_best_params)\n",
    "print(\"Random Forest - Pearson Correlation Scores:\", rf_best_scores)\n",
    "print(\"Random Forest - Mean Pearson Correlation:\", rf_best_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosting Parameters\n",
    "gb_params = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"subsample\": [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Gradient Boosting Model\n",
    "gb_model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Grid Search for Gradient Boosting\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, cv=10, scoring=pearson_scorer, n_jobs=-1)\n",
    "gb_grid.fit(features_train, train_data[\"score\"])\n",
    "\n",
    "# Best Model and Parameters\n",
    "gb_best_model = gb_grid.best_estimator_\n",
    "gb_best_params = gb_grid.best_params_\n",
    "\n",
    "# Cross-validation with the best model\n",
    "gb_best_scores = cross_val_score(gb_best_model, features_train, train_data[\"score\"], cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Gradient Boosting - Best Parameters:\", gb_best_params)\n",
    "print(\"Gradient Boosting - Pearson Correlation Scores:\", gb_best_scores)\n",
    "print(\"Gradient Boosting - Mean Pearson Correlation:\", gb_best_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_summary = {\n",
    "    \"Linear Regression\": {\"Mean Pearson CV Score\": linear_scores.mean()},\n",
    "    \"Random Forest\": {\"Mean Pearson CV Score\": rf_best_scores.mean()},\n",
    "    \"Gradient Boosting\": {\"Mean Pearson CV Score\": gb_best_scores.mean()},\n",
    "}\n",
    "\n",
    "models_df = pd.DataFrame(models_summary).T\n",
    "print(models_df)\n",
    "\n",
    "best_model_name = models_df[\"Mean Pearson CV Score\"].idxmax()\n",
    "best_model_score = models_df[\"Mean Pearson CV Score\"].max()\n",
    "\n",
    "print(f\"Best Model: {best_model_name} with a Mean Pearson CV Score of {best_model_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
