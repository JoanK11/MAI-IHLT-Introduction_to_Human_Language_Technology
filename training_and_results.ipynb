{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will implement and train three different types of classifiers to ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Training and Test Datasets\n",
    "train_data = pd.read_csv('datasets/train_preprocessed.csv')\n",
    "test_data  = pd.read_csv('datasets/test_preprocessed.csv')\n",
    "\n",
    "# Load Training and Test Features\n",
    "features_train = pd.read_csv('features/features_train2.csv')\n",
    "features_test  = pd.read_csv('features/features_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "features_train_shuffled, score_shuffled = shuffle(features_train, train_data[\"score\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "for col in [\"longest_common_substring\", \"longest_common_subsequence\", \"greedy_string_tiling\",'3_gram_word_Jaccard', '4_gram_word_Jaccard', '2_gram_word_Jaccard_without_SW', '2_gram_word_Jaccard_without_SW', \"pathlen_similarity\", \"lin_similarity\"]:\n",
    "    features_train[col] = np.log1p(features_train[col])\n",
    "\n",
    "\n",
    "features_train[[\"2_gram_char\", \"lexical_substitution_system\"]] = power_transformer.fit_transform(features_train[[\"2_gram_char\", \"lexical_substitution_system\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we implemented is the Linear Regression model. We selected this model due to it was used in the UKP paper [1]. We followed their same \"process\" using a 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Pearson Correlation Scores: [0.77835537 0.7667178  0.78716194 0.85520775 0.76680148 0.81712407\n",
      " 0.76953242 0.79999424 0.84274563 0.83556031]\n",
      "Linear Regression - Mean Pearson Correlation: 0.8019201003257639\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def pearson_corr(y_true, y_pred):\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "pearson_scorer = make_scorer(pearson_corr, greater_is_better=True)\n",
    "\n",
    "# Linear Regression Model\n",
    "linear_model = LinearRegression()\n",
    "# Cross-validation\n",
    "linear_scores = cross_val_score(linear_model, features_train_shuffled, score_shuffled, cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Linear Regression - Pearson Correlation Scores:\", linear_scores)\n",
    "print(\"Linear Regression - Mean Pearson Correlation:\", linear_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Best Parameters: {'max_depth': 15, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Random Forest - Pearson Correlation Scores: [0.82106607 0.83467509 0.8530833  0.8896091  0.81747197 0.88078393\n",
      " 0.8341949  0.84349109 0.89520229 0.88602622]\n",
      "Random Forest - Mean Pearson Correlation: 0.8555603961216758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Parameters\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 400],\n",
    "    \"max_depth\": [15, 20, 25], #None crec que funciona millor\n",
    "    \"min_samples_split\": [2, 5]\n",
    "}\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Grid Search for Random Forest\n",
    "rf_grid = GridSearchCV(rf_model, rf_params, cv=10, scoring=pearson_scorer, n_jobs=-1)\n",
    "rf_grid.fit(features_train_shuffled, score_shuffled)\n",
    "\n",
    "# Best Model and Parameters\n",
    "rf_best_model = rf_grid.best_estimator_\n",
    "rf_best_params = rf_grid.best_params_\n",
    "\n",
    "# Cross-validation with the best model\n",
    "rf_best_scores = cross_val_score(rf_best_model, features_train_shuffled, score_shuffled, cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Random Forest - Best Parameters:\", rf_best_params)\n",
    "print(\"Random Forest - Pearson Correlation Scores:\", rf_best_scores)\n",
    "print(\"Random Forest - Mean Pearson Correlation:\", rf_best_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Gradient Boosting - Pearson Correlation Scores: [0.57324476 0.56447931 0.51679637 0.70493078 0.79600003 0.77431305\n",
      " 0.90360158 0.7544465  0.67282511 0.64644695]\n",
      "Gradient Boosting - Mean Pearson Correlation: 0.6907084439881572\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosting Parameters\n",
    "gb_params = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [100, 150],\n",
    "    \"max_depth\": [5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"subsample\": [0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Gradient Boosting Model\n",
    "gb_model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# Grid Search for Gradient Boosting\n",
    "gb_grid = GridSearchCV(gb_model, gb_params, cv=10, scoring=pearson_scorer, n_jobs=-1)\n",
    "gb_grid.fit(features_train, train_data[\"score\"])\n",
    "\n",
    "# Best Model and Parameters\n",
    "gb_best_model = gb_grid.best_estimator_\n",
    "gb_best_params = gb_grid.best_params_\n",
    "\n",
    "# Cross-validation with the best model\n",
    "gb_best_scores = cross_val_score(gb_best_model, features_train, train_data[\"score\"], cv=10, scoring=pearson_scorer)\n",
    "\n",
    "print(\"Gradient Boosting - Best Parameters:\", gb_best_params)\n",
    "print(\"Gradient Boosting - Pearson Correlation Scores:\", gb_best_scores)\n",
    "print(\"Gradient Boosting - Mean Pearson Correlation:\", gb_best_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Mean Pearson CV Score\n",
      "Linear Regression               0.801920\n",
      "Random Forest                   0.850097\n",
      "Gradient Boosting               0.690708\n",
      "Best Model: Random Forest with a Mean Pearson CV Score of 0.8500973394498722\n"
     ]
    }
   ],
   "source": [
    "models_summary = {\n",
    "    \"Linear Regression\": {\"Mean Pearson CV Score\": linear_scores.mean()},\n",
    "    \"Random Forest\": {\"Mean Pearson CV Score\": rf_best_scores.mean()},\n",
    "    \"Gradient Boosting\": {\"Mean Pearson CV Score\": gb_best_scores.mean()},\n",
    "}\n",
    "\n",
    "models_df = pd.DataFrame(models_summary).T\n",
    "print(models_df)\n",
    "\n",
    "best_model_name = models_df[\"Mean Pearson CV Score\"].idxmax()\n",
    "best_model_score = models_df[\"Mean Pearson CV Score\"].max()\n",
    "\n",
    "print(f\"Best Model: {best_model_name} with a Mean Pearson CV Score of {best_model_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"longest_common_substring\", \"longest_common_subsequence\", \"greedy_string_tiling\",'3_gram_word_Jaccard', '4_gram_word_Jaccard', '2_gram_word_Jaccard_without_SW', '2_gram_word_Jaccard_without_SW', \"pathlen_similarity\", \"lin_similarity\"]:\n",
    "    features_test[col] = np.log1p(features_test[col])\n",
    "\n",
    "features_test[[\"2_gram_char\", \"lexical_substitution_system\"]] = power_transformer.transform(features_test[[\"2_gram_char\", \"lexical_substitution_system\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- wordnet_augmented_overlap\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y_true \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pearson_corr \u001b[38;5;241m=\u001b[39m pearsonr(y_true, y_pred)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPearson Correlation:\u001b[39m\u001b[38;5;124m\"\u001b[39m, pearson_corr)\n",
      "File \u001b[1;32mc:\\Users\\joanc\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:2125\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   2111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   2112\u001b[0m \n\u001b[0;32m   2113\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2125\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   2127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2128\u001b[0m     \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\joanc\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\joanc\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- wordnet_augmented_overlap\n"
     ]
    }
   ],
   "source": [
    "y_true = test_data[\"score\"]\n",
    "\n",
    "y_pred = model.predict(features_test)\n",
    "pearson_corr = pearsonr(y_true, y_pred)[0]\n",
    "print(\"Pearson Correlation:\", pearson_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **. Comparison with Official Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain Official Results\n",
    "official_results = pd.read_csv('results/official_results.csv')\n",
    "\n",
    "# Calculate Our Best Results\n",
    "\n",
    "# Add Our Best Results to the Official Results\n",
    "\n",
    "# Compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
